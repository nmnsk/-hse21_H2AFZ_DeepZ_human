{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2-BioInf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UwUhtSBRO5jB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pybedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PWPDSwPBsPF",
        "outputId": "f2b720bb-6e26-474e-8f36-f90287b87c76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pybedtools in /usr/local/lib/python3.7/dist-packages (0.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pybedtools) (1.15.0)\n",
            "Requirement already satisfied: pysam in /usr/local/lib/python3.7/dist-packages (from pybedtools) (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get install bedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBY3wQ2UByhD",
        "outputId": "2c486cbc-f07c-4937-ad4f-b6589c22a54f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "bedtools is already the newest version (2.26.0+dfsg-5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/arq5x/bedtools2/releases/download/v2.30.0/bedtools.static.binary\n",
        "!mv bedtools.static.binary bedtools\n",
        "!chmod a+x bedtools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWS-kucSBziG",
        "outputId": "1f30b23b-2e14-4116-e31a-83c1e3a9b0e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 00:39:24--  https://github.com/arq5x/bedtools2/releases/download/v2.30.0/bedtools.static.binary\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/15059334/c633cf80-61f8-11eb-92ef-18b90dff37e2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211201T003924Z&X-Amz-Expires=300&X-Amz-Signature=3263a39d9caae804deebd21c0a409cb47d31fb511bccd1f706781ae1df6649b7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=15059334&response-content-disposition=attachment%3B%20filename%3Dbedtools.static.binary&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-01 00:39:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/15059334/c633cf80-61f8-11eb-92ef-18b90dff37e2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211201T003924Z&X-Amz-Expires=300&X-Amz-Signature=3263a39d9caae804deebd21c0a409cb47d31fb511bccd1f706781ae1df6649b7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=15059334&response-content-disposition=attachment%3B%20filename%3Dbedtools.static.binary&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41993576 (40M) [application/octet-stream]\n",
            "Saving to: ‘bedtools.static.binary’\n",
            "\n",
            "bedtools.static.bin 100%[===================>]  40.05M  85.0MB/s    in 0.5s    \n",
            "\n",
            "2021-12-01 00:39:25 (85.0 MB/s) - ‘bedtools.static.binary’ saved [41993576/41993576]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем участки с пересечением вторичной структуры и гистоновой метки "
      ],
      "metadata": {
        "id": "lSBrDrPuNvGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ORzEf6bC8muE",
        "outputId": "bfa78c38-96d5-4267-d458-d07fb608552c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0c6415f5-8fd9-449e-a415-5db431db6605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chr</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chr1</td>\n",
              "      <td>762682</td>\n",
              "      <td>762898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chr1</td>\n",
              "      <td>840032</td>\n",
              "      <td>840251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chr1</td>\n",
              "      <td>859216</td>\n",
              "      <td>859231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chr1</td>\n",
              "      <td>894548</td>\n",
              "      <td>894874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chr1</td>\n",
              "      <td>934027</td>\n",
              "      <td>934082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13948</th>\n",
              "      <td>chrX</td>\n",
              "      <td>153991024</td>\n",
              "      <td>153991239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13949</th>\n",
              "      <td>chrX</td>\n",
              "      <td>153991273</td>\n",
              "      <td>153991339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13950</th>\n",
              "      <td>chrX</td>\n",
              "      <td>154299314</td>\n",
              "      <td>154299368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13951</th>\n",
              "      <td>chrX</td>\n",
              "      <td>154299391</td>\n",
              "      <td>154299420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13952</th>\n",
              "      <td>chrX</td>\n",
              "      <td>154299648</td>\n",
              "      <td>154299918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13953 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c6415f5-8fd9-449e-a415-5db431db6605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c6415f5-8fd9-449e-a415-5db431db6605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c6415f5-8fd9-449e-a415-5db431db6605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        chr      start        end\n",
              "0      chr1     762682     762898\n",
              "1      chr1     840032     840251\n",
              "2      chr1     859216     859231\n",
              "3      chr1     894548     894874\n",
              "4      chr1     934027     934082\n",
              "...     ...        ...        ...\n",
              "13948  chrX  153991024  153991239\n",
              "13949  chrX  153991273  153991339\n",
              "13950  chrX  154299314  154299368\n",
              "13951  chrX  154299391  154299420\n",
              "13952  chrX  154299648  154299918\n",
              "\n",
              "[13953 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "H2AFZ_deepz = 'H2AFZ.intersect_with_DeepZ.bed'\n",
        "H2AFZ_deepz = pd.read_csv(H2AFZ_deepz, sep='\\t', names=['chr', 'start', 'end'])\n",
        "H2AFZ_deepz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#добавим колонку с длиной \n",
        "\n",
        "H2AFZ_deepz['len'] = H2AFZ_deepz['end'] - H2AFZ_deepz['start']\n",
        "H2AFZ_deepz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "agN8JmviOpcT",
        "outputId": "9c5389f7-5f51-4023-df67-5b5d89367c98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-82202c88-0b78-4773-9645-e35a0d3c48e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chr</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chr1</td>\n",
              "      <td>762682</td>\n",
              "      <td>762898</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chr1</td>\n",
              "      <td>840032</td>\n",
              "      <td>840251</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chr1</td>\n",
              "      <td>859216</td>\n",
              "      <td>859231</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chr1</td>\n",
              "      <td>894548</td>\n",
              "      <td>894874</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chr1</td>\n",
              "      <td>934027</td>\n",
              "      <td>934082</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13948</th>\n",
              "      <td>chrX</td>\n",
              "      <td>153991024</td>\n",
              "      <td>153991239</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13949</th>\n",
              "      <td>chrX</td>\n",
              "      <td>153991273</td>\n",
              "      <td>153991339</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13950</th>\n",
              "      <td>chrX</td>\n",
              "      <td>154299314</td>\n",
              "      <td>154299368</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13951</th>\n",
              "      <td>chrX</td>\n",
              "      <td>154299391</td>\n",
              "      <td>154299420</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13952</th>\n",
              "      <td>chrX</td>\n",
              "      <td>154299648</td>\n",
              "      <td>154299918</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13953 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82202c88-0b78-4773-9645-e35a0d3c48e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82202c88-0b78-4773-9645-e35a0d3c48e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82202c88-0b78-4773-9645-e35a0d3c48e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        chr      start        end  len\n",
              "0      chr1     762682     762898  216\n",
              "1      chr1     840032     840251  219\n",
              "2      chr1     859216     859231   15\n",
              "3      chr1     894548     894874  326\n",
              "4      chr1     934027     934082   55\n",
              "...     ...        ...        ...  ...\n",
              "13948  chrX  153991024  153991239  215\n",
              "13949  chrX  153991273  153991339   66\n",
              "13950  chrX  154299314  154299368   54\n",
              "13951  chrX  154299391  154299420   29\n",
              "13952  chrX  154299648  154299918  270\n",
              "\n",
              "[13953 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#найдем чаще всего встречающееся значение\n",
        "H2AFZ_deepz['len'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFDHAL2BQa7T",
        "outputId": "c3b417d0-e4f6-49d5-c04a-bcf4fefd25f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11      287\n",
              "12      265\n",
              "15      242\n",
              "14      236\n",
              "13      236\n",
              "       ... \n",
              "573       1\n",
              "581       1\n",
              "597       1\n",
              "605       1\n",
              "1007      1\n",
              "Name: len, Length: 722, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получили, что чаще всего встречаются последовательности длины 11, значит они и будут в positive"
      ],
      "metadata": {
        "id": "U7IiD8eoa_zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive = H2AFZ_deepz[H2AFZ_deepz['len'] == 11]"
      ],
      "metadata": {
        "id": "JHaTdWOmYr9v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы хотим центрировать участки"
      ],
      "metadata": {
        "id": "hMXHEHD0nt-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive['centre'] = positive['start'] + (positive['len'] // 2)\n",
        "positive['start'], positive['end'] = positive['centre'] - 100, positive['centre'] + 100\n",
        "positive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "UXHO6Plgnph5",
        "outputId": "2db91c68-3337-416e-cd86-449202e0562e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d41c517f-a259-4f30-976d-249ba7aa75e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chr</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>len</th>\n",
              "      <th>centre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>chr1</td>\n",
              "      <td>8021280</td>\n",
              "      <td>8021480</td>\n",
              "      <td>11</td>\n",
              "      <td>8021380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>chr1</td>\n",
              "      <td>8484467</td>\n",
              "      <td>8484667</td>\n",
              "      <td>11</td>\n",
              "      <td>8484567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>chr1</td>\n",
              "      <td>8586217</td>\n",
              "      <td>8586417</td>\n",
              "      <td>11</td>\n",
              "      <td>8586317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>chr1</td>\n",
              "      <td>10532417</td>\n",
              "      <td>10532617</td>\n",
              "      <td>11</td>\n",
              "      <td>10532517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>chr1</td>\n",
              "      <td>32479502</td>\n",
              "      <td>32479702</td>\n",
              "      <td>11</td>\n",
              "      <td>32479602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13630</th>\n",
              "      <td>chr22</td>\n",
              "      <td>42229069</td>\n",
              "      <td>42229269</td>\n",
              "      <td>11</td>\n",
              "      <td>42229169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13665</th>\n",
              "      <td>chr22</td>\n",
              "      <td>47158721</td>\n",
              "      <td>47158921</td>\n",
              "      <td>11</td>\n",
              "      <td>47158821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13688</th>\n",
              "      <td>chrX</td>\n",
              "      <td>348044</td>\n",
              "      <td>348244</td>\n",
              "      <td>11</td>\n",
              "      <td>348144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13840</th>\n",
              "      <td>chrX</td>\n",
              "      <td>84498636</td>\n",
              "      <td>84498836</td>\n",
              "      <td>11</td>\n",
              "      <td>84498736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13942</th>\n",
              "      <td>chrX</td>\n",
              "      <td>153718878</td>\n",
              "      <td>153719078</td>\n",
              "      <td>11</td>\n",
              "      <td>153718978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>287 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d41c517f-a259-4f30-976d-249ba7aa75e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d41c517f-a259-4f30-976d-249ba7aa75e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d41c517f-a259-4f30-976d-249ba7aa75e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         chr      start        end  len     centre\n",
              "86      chr1    8021280    8021480   11    8021380\n",
              "90      chr1    8484467    8484667   11    8484567\n",
              "93      chr1    8586217    8586417   11    8586317\n",
              "120     chr1   10532417   10532617   11   10532517\n",
              "307     chr1   32479502   32479702   11   32479602\n",
              "...      ...        ...        ...  ...        ...\n",
              "13630  chr22   42229069   42229269   11   42229169\n",
              "13665  chr22   47158721   47158921   11   47158821\n",
              "13688   chrX     348044     348244   11     348144\n",
              "13840   chrX   84498636   84498836   11   84498736\n",
              "13942   chrX  153718878  153719078   11  153718978\n",
              "\n",
              "[287 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#хотим проверить, есть ли повторения, и если да - удалить\n",
        "\n",
        "positive.drop_duplicates()\n",
        "positive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Cq6JJvGPrcqg",
        "outputId": "60d8a3a0-c464-4d6e-a6d1-63bf6a32c953"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0403193c-cf77-4731-8e49-f00891f39c21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chr</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>len</th>\n",
              "      <th>centre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>chr1</td>\n",
              "      <td>8021280</td>\n",
              "      <td>8021480</td>\n",
              "      <td>11</td>\n",
              "      <td>8021380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>chr1</td>\n",
              "      <td>8484467</td>\n",
              "      <td>8484667</td>\n",
              "      <td>11</td>\n",
              "      <td>8484567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>chr1</td>\n",
              "      <td>8586217</td>\n",
              "      <td>8586417</td>\n",
              "      <td>11</td>\n",
              "      <td>8586317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>chr1</td>\n",
              "      <td>10532417</td>\n",
              "      <td>10532617</td>\n",
              "      <td>11</td>\n",
              "      <td>10532517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>chr1</td>\n",
              "      <td>32479502</td>\n",
              "      <td>32479702</td>\n",
              "      <td>11</td>\n",
              "      <td>32479602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13630</th>\n",
              "      <td>chr22</td>\n",
              "      <td>42229069</td>\n",
              "      <td>42229269</td>\n",
              "      <td>11</td>\n",
              "      <td>42229169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13665</th>\n",
              "      <td>chr22</td>\n",
              "      <td>47158721</td>\n",
              "      <td>47158921</td>\n",
              "      <td>11</td>\n",
              "      <td>47158821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13688</th>\n",
              "      <td>chrX</td>\n",
              "      <td>348044</td>\n",
              "      <td>348244</td>\n",
              "      <td>11</td>\n",
              "      <td>348144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13840</th>\n",
              "      <td>chrX</td>\n",
              "      <td>84498636</td>\n",
              "      <td>84498836</td>\n",
              "      <td>11</td>\n",
              "      <td>84498736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13942</th>\n",
              "      <td>chrX</td>\n",
              "      <td>153718878</td>\n",
              "      <td>153719078</td>\n",
              "      <td>11</td>\n",
              "      <td>153718978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>287 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0403193c-cf77-4731-8e49-f00891f39c21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0403193c-cf77-4731-8e49-f00891f39c21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0403193c-cf77-4731-8e49-f00891f39c21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         chr      start        end  len     centre\n",
              "86      chr1    8021280    8021480   11    8021380\n",
              "90      chr1    8484467    8484667   11    8484567\n",
              "93      chr1    8586217    8586417   11    8586317\n",
              "120     chr1   10532417   10532617   11   10532517\n",
              "307     chr1   32479502   32479702   11   32479602\n",
              "...      ...        ...        ...  ...        ...\n",
              "13630  chr22   42229069   42229269   11   42229169\n",
              "13665  chr22   47158721   47158921   11   47158821\n",
              "13688   chrX     348044     348244   11     348144\n",
              "13840   chrX   84498636   84498836   11   84498736\n",
              "13942   chrX  153718878  153719078   11  153718978\n",
              "\n",
              "[287 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут мы получили, что количество строк не изменилось, а значит повторений нет. Теперь приведем positive в формат fasta для дальнейшего обучения"
      ],
      "metadata": {
        "id": "aqFg3FqCNnkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa\n",
        "!chmod a+x twoBitToFa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG_1ePsaN-H-",
        "outputId": "11e8593d-29fb-4d73-9ac6-4ce5d0a8f166"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 00:39:44--  http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa\n",
            "Resolving hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9375024 (8.9M)\n",
            "Saving to: ‘twoBitToFa.1’\n",
            "\n",
            "twoBitToFa.1        100%[===================>]   8.94M  11.7MB/s    in 0.8s    \n",
            "\n",
            "2021-12-01 00:39:45 (11.7 MB/s) - ‘twoBitToFa.1’ saved [9375024/9375024]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " for i in range(positive.shape[0]):\n",
        "    name = positive.iloc[i, :]['chr']\n",
        "    start = positive.iloc[i, :]['start']\n",
        "    end = positive.iloc[i, :]['end']\n",
        "    file_name = str(i) + 'z.fa'\n",
        "    \n",
        "    !./twoBitToFa http://hgdownload.cse.ucsc.edu/gbdb/hg19/hg19.2bit $file_name -seq=$name -start=$start -end=$end"
      ],
      "metadata": {
        "id": "5lL4bOs7Nl5r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat *z.fa > pos.fa"
      ],
      "metadata": {
        "id": "P5CuYhEEN_0T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь займемся созданием класса negative. Для этого исключим из генома пересечения с вторичной структурой и гист. метками"
      ],
      "metadata": {
        "id": "5Vi0hVBYt72h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bedtools subtract -a Genome.bed -b DeepZ.bed > exclude_deepz.bed\n",
        "!bedtools subtract -a exclude_deepz.bed -b H2AFZ.merge.hg19.bed > negative.bed"
      ],
      "metadata": {
        "id": "Y0547Dq-t5DA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative = pd.read_csv('negative.bed', sep='\\t')\n",
        "negative.columns = ['chr', 'start', 'end', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
        "negative.loc[negative['end'] - negative['start'] >= 200, 'end'] = negative['start'] + 200\n",
        "negative = negative.loc[negative['end'] - negative['start'] == 200].sample(1000)\n",
        "negative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "SwnI8ytWCVcj",
        "outputId": "821006c6-2235-45bc-8426-08c1b83a7fd6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-071f9754-91a4-46d3-8c5a-5ef94df0c7c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chr</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>270580</th>\n",
              "      <td>chr18</td>\n",
              "      <td>12318791</td>\n",
              "      <td>12318991</td>\n",
              "      <td>NM_001303529.3</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>12325226</td>\n",
              "      <td>12326129</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>109,109,111,1761,</td>\n",
              "      <td>0,446,2702,16568,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9645</th>\n",
              "      <td>chr1</td>\n",
              "      <td>155580141</td>\n",
              "      <td>155580341</td>\n",
              "      <td>NM_001350777.1</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>155581614</td>\n",
              "      <td>155584064</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>163,136,70,76,55,164,118,135,153,132,185,105,1...</td>\n",
              "      <td>0,255,869,1046,1379,1519,1813,2012,2248,2674,2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156219</th>\n",
              "      <td>chr9</td>\n",
              "      <td>35277651</td>\n",
              "      <td>35277851</td>\n",
              "      <td>NM_001387554.1</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>35231211</td>\n",
              "      <td>35404030</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>219,30,100,118,124,74,58,235,315,91,47,79,75,2...</td>\n",
              "      <td>0,300,3405,8754,9988,15576,31278,67981,82752,8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285873</th>\n",
              "      <td>chr19</td>\n",
              "      <td>21702634</td>\n",
              "      <td>21702834</td>\n",
              "      <td>NM_001001415.4</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>21688573</td>\n",
              "      <td>21720880</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>173,127,96,4389,</td>\n",
              "      <td>0,24056,24987,30678,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27189</th>\n",
              "      <td>chr2</td>\n",
              "      <td>47206098</td>\n",
              "      <td>47206298</td>\n",
              "      <td>NM_020458.4</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>47168680</td>\n",
              "      <td>47301062</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>502,164,169,131,116,79,158,64,138,84,105,118,5...</td>\n",
              "      <td>0,9139,15615,33749,37568,52226,53133,53912,646...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95142</th>\n",
              "      <td>chr5</td>\n",
              "      <td>88729708</td>\n",
              "      <td>88729908</td>\n",
              "      <td>NR_136221.1</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>88763398</td>\n",
              "      <td>88763398</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>82,62,75,71,80,110,1666,</td>\n",
              "      <td>0,15596,76228,205346,487670,576053,576303,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247428</th>\n",
              "      <td>chr15</td>\n",
              "      <td>91525712</td>\n",
              "      <td>91525912</td>\n",
              "      <td>NM_003981.4</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>91510360</td>\n",
              "      <td>91537647</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>1163,42,177,111,111,147,96,137,148,150,171,234...</td>\n",
              "      <td>0,3039,3407,4364,8096,8545,10636,13118,14202,1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24129</th>\n",
              "      <td>chr1</td>\n",
              "      <td>205199819</td>\n",
              "      <td>205200019</td>\n",
              "      <td>NM_001375652.1</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>205210659</td>\n",
              "      <td>205241252</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>455,189,540,935,136,1531,</td>\n",
              "      <td>0,11017,11790,39235,41405,42098,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117073</th>\n",
              "      <td>chr6</td>\n",
              "      <td>49519788</td>\n",
              "      <td>49519988</td>\n",
              "      <td>NR_146855.2</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>49528647</td>\n",
              "      <td>49528647</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1008,281,401,</td>\n",
              "      <td>0,4209,9866,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129057</th>\n",
              "      <td>chr7</td>\n",
              "      <td>96110937</td>\n",
              "      <td>96111137</td>\n",
              "      <td>NR_163953.1</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>96339158</td>\n",
              "      <td>96339158</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2363,215,58,76,94,159,</td>\n",
              "      <td>0,4577,14658,24997,213172,228062,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-071f9754-91a4-46d3-8c5a-5ef94df0c7c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-071f9754-91a4-46d3-8c5a-5ef94df0c7c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-071f9754-91a4-46d3-8c5a-5ef94df0c7c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          chr  ...                                                 12\n",
              "270580  chr18  ...                                  0,446,2702,16568,\n",
              "9645     chr1  ...  0,255,869,1046,1379,1519,1813,2012,2248,2674,2...\n",
              "156219   chr9  ...  0,300,3405,8754,9988,15576,31278,67981,82752,8...\n",
              "285873  chr19  ...                               0,24056,24987,30678,\n",
              "27189    chr2  ...  0,9139,15615,33749,37568,52226,53133,53912,646...\n",
              "...       ...  ...                                                ...\n",
              "95142    chr5  ...         0,15596,76228,205346,487670,576053,576303,\n",
              "247428  chr15  ...  0,3039,3407,4364,8096,8545,10636,13118,14202,1...\n",
              "24129    chr1  ...                   0,11017,11790,39235,41405,42098,\n",
              "117073   chr6  ...                                       0,4209,9866,\n",
              "129057   chr7  ...                  0,4577,14658,24997,213172,228062,\n",
              "\n",
              "[1000 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "оставляем только нужное"
      ],
      "metadata": {
        "id": "QeDj_2r8MKiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "negative[[\"chr\", \"start\", \"end\", \"4\"]].to_csv('neg.bed', index=None, sep=\"\\t\", header=None)\n",
        "!head neg.bed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw9y7vm0LU4S",
        "outputId": "a92492b7-2266-4ff1-b59a-b43763083bf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chr18\t12318791\t12318991\tNM_001303529.3\n",
            "chr1\t155580141\t155580341\tNM_001350777.1\n",
            "chr9\t35277651\t35277851\tNM_001387554.1\n",
            "chr19\t21702634\t21702834\tNM_001001415.4\n",
            "chr2\t47206098\t47206298\tNM_020458.4\n",
            "chr14\t62475106\t62475306\tNM_001367661.1\n",
            "chr8\t53086234\t53086434\tNM_001352878.2\n",
            "chr9\t37010656\t37010856\tNM_001280549.2\n",
            "chr1\t171154346\t171154546\tNM_001365900.1\n",
            "chr3\t58406235\t58406435\tNM_001349495.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем из neg файл типа fasta, чтобы можно было перейти непосредственно к обучению"
      ],
      "metadata": {
        "id": "JaRw5FWSMdFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa\n",
        "!chmod a+x twoBitToFa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLdhuKfuMQs8",
        "outputId": "dfcd816d-5f9c-477a-8a65-613e0195c6b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 00:44:15--  http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa\n",
            "Resolving hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9375024 (8.9M)\n",
            "Saving to: ‘twoBitToFa.2’\n",
            "\n",
            "twoBitToFa.2        100%[===================>]   8.94M  11.7MB/s    in 0.8s    \n",
            "\n",
            "2021-12-01 00:44:16 (11.7 MB/s) - ‘twoBitToFa.2’ saved [9375024/9375024]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./twoBitToFa http://hgdownload.cse.ucsc.edu/gbdb/hg19/hg19.2bit -bed=neg.bed neg.fa"
      ],
      "metadata": {
        "id": "KyalPPuvPbkC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head neg.fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbafffMXPcLa",
        "outputId": "a2eeec41-367c-481b-eead-73ec969957c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">NM_001303529.3\n",
            "tgtcacccaggctggagtgcagtggtgtgatcatagctcactgtagcctc\n",
            "aaactcctgggctcaagcagtcctcccacttcaccctcctgtgctaggat\n",
            "tgcaggtgtgagcTCCCATAGCTGGTCTTATACAAAAAAAAGTGTTTAAT\n",
            "GTTTTCATGTCAAAGTTAAAACAAAGTGCTTGTACATGGTTTTTTCAAAC\n",
            ">NM_001350777.1\n",
            "TGCCCCCGAGGAGCCCTTCGGGATCTACAGTCCCGACGTTCAGCCGGCCT\n",
            "GCCTCGTCCTCTCTGCTTCCCCAGGATGCTGCGCTGGGCCGAGCGACCGA\n",
            "TTCCAAGGAGCCCCCGGGAGAGCTGTGCCCCGACGTCCTGTATCGTACGG\n",
            "GCCGGACGCTGCACGGCCAGGAGACCTACACGCCGCGACTCATCCTCATG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь воспользуемся кодом с семинара, чтобы обучить модель"
      ],
      "metadata": {
        "id": "Xh9_3k26Twxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "__author__ = 'jasperz'\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import time\n",
        "import math\n",
        "import sys"
      ],
      "metadata": {
        "id": "bY8VKGqrUDPb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An object of this class represents a neural network, which you can build, print, train, evaluate, save and load.\n",
        "# Below, the functions are discussed in detail.\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "class NetworkModel:\n",
        "    tf.disable_v2_behavior()\n",
        "\n",
        "    # The constructor function\n",
        "    def __init__(self, file_to_load = None):\n",
        "        tf.reset_default_graph()\n",
        "        self.all_layers = []\n",
        "\n",
        "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
        "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
        "        config.gpu_options.allow_growth = True\n",
        "\n",
        "        self.sess = tf.Session(config=config)\n",
        "\n",
        "        if not file_to_load:\n",
        "            self.X_placeholder = tf.placeholder(tf.float32, [None, 200, 4],name='X_placeholder')\n",
        "            self.Y_placeholder = tf.placeholder(tf.float32, [None, 2],name='Y_placeholder')\n",
        "            self.loaded = False\n",
        "            self.nn = None\n",
        "        else:\n",
        "            self.loaded = True\n",
        "            self._loadNetworkParameters('models/'+file_to_load)\n",
        "            self.X_placeholder = tf.get_default_graph().get_tensor_by_name('X_placeholder:0')\n",
        "            self.Y_placeholder = tf.get_default_graph().get_tensor_by_name('Y_placeholder:0')\n",
        "            self.predictions_softmax = tf.get_default_graph().get_tensor_by_name('softmax_prediction:0')\n",
        "\n",
        "    # Adding the input layer\n",
        "    def addInputLayer(self):\n",
        "        assert len(self.all_layers) == 0, 'The input layer should be the first layer of the network, and can only be added once.'\n",
        "        self.all_layers.append(('Input layer','',self.X_placeholder))\n",
        "\n",
        "    # Adding a convolution layer\n",
        "    def addConvLayer(self, num_of_filters, filter_width, zero_padding = True):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert zero_padding in (True,False), 'zero_padding should be True or False (boolean)'\n",
        "        assert 0 < num_of_filters < 500, 'The number of filters specified should be a positive number, smaller than 500'\n",
        "        assert 0 < filter_width < 64, 'The width of your filters should be a positive number, smaller than 64'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        assert 'Fully-connected layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a convolutional layer after a fully-connected layer'\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a convolutional layer after a softmax layer'\n",
        "        prev_width = self.all_layers[-1][-1].shape[1]\n",
        "        assert zero_padding or prev_width >= filter_width, 'You cannot add a (non-zeropadded) convolution of width {} when the previous layer has an output width of {}'.format(filter_width,prev_width)\n",
        "        self.all_layers.append(('Convolutional layer',\n",
        "                                '{} filters, width {}, {}zero padding, with ReLU'.format(num_of_filters,\n",
        "                                                                                         filter_width,\n",
        "                                                                                         'no ' if not zero_padding else ''),\n",
        "                                tf.layers.conv1d(self.all_layers[-1][-1],\n",
        "                                                 filters=num_of_filters,\n",
        "                                                 kernel_size=filter_width,\n",
        "                                                 activation=tf.nn.relu,\n",
        "                                                 padding='same' if zero_padding else 'valid')))\n",
        "\n",
        "    # Adding a max pooling layer\n",
        "    def addMaxPoolLayer(self, pool_size):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert 'Fully-connected layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a pooling layer after a fully-connected layer'\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a pooling layer after a softmax layer'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        assert 0 < pool_size < 50, 'The pool size should be lower than 50'\n",
        "        prev_width = self.all_layers[-1][-1].shape[1]\n",
        "        assert prev_width >= pool_size, 'You cannot add a pooling layer with pool size {} when the previous layer has an output width of {}'.format(pool_size,prev_width)\n",
        "        self.all_layers.append(('Max pooling layer',\n",
        "                                'pool size {}'.format(pool_size),\n",
        "                                tf.layers.max_pooling1d(self.all_layers[-1][-1],\n",
        "                                                        pool_size=pool_size,\n",
        "                                                        strides=pool_size)))\n",
        "\n",
        "    # Adding a fully-connected layer\n",
        "    def addFullyConnectedLayer(self,num_of_neurons):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a fully-connected layer after a softmax layer'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        assert 0 < num_of_neurons < 1000, 'The amount of neurons in this layer should be a positive number, lower than 2000'\n",
        "        if len(self.all_layers[-1][-1].shape) > 2:\n",
        "            self.all_layers.append(('Flatten layer',\n",
        "                                    '',\n",
        "                                   tf.layers.flatten(self.all_layers[-1][-1])))\n",
        "        self.all_layers.append(('Fully-connected layer',\n",
        "                                '{} neurons, with ReLU'.format(num_of_neurons),\n",
        "                                tf.layers.dense(self.all_layers[-1][-1],num_of_neurons)))\n",
        "\n",
        "    # Adding an output layer\n",
        "    def addOutputLayer(self):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a softmax (output) layer after a softmax layer'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        if len(self.all_layers[-1][-1].shape) > 2:\n",
        "            self.all_layers.append(('Flatten layer',\n",
        "                                    '',\n",
        "                                    tf.contrib.layers.flatten(self.all_layers[-1][-1])))\n",
        "        # assert no output layer yet\n",
        "        # assert # of layers\n",
        "        self.all_layers.append(('Softmax (output) layer',\n",
        "                                '2 neurons',\n",
        "                                tf.layers.dense(self.all_layers[-1][-1], 2,name='logits')))\n",
        "\n",
        "    # Printing out an overview of the layers\n",
        "    def printDetails(self):\n",
        "        print('####################################')\n",
        "        print('Network information:')\n",
        "        # count all parameters:\n",
        "        total_parameters = 0\n",
        "        # iterating over all variables\n",
        "        for variable in tf.trainable_variables():\n",
        "            local_parameters = 1\n",
        "            shape = variable.get_shape()  # getting shape of a variable\n",
        "            for i in shape:\n",
        "                local_parameters *= i.value  # mutiplying dimension values\n",
        "            total_parameters += local_parameters\n",
        "        print('This network has {} trainable parameters.'.format(total_parameters))\n",
        "\n",
        "        for i,(name,info,l) in enumerate(self.all_layers):\n",
        "            try:\n",
        "                print('{: >2d}. {:23} {:50} -> Output size: {}'.format(i, name, info, l.shape))\n",
        "            except AttributeError:\n",
        "                pass\n",
        "        print('')\n",
        "        print('####################################')\n",
        "\n",
        "    # Function to train the network\n",
        "    def train(self, trainX, trainY, validX, validY, n_epochs):\n",
        "        print('####################################')\n",
        "        assert 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot train a model without an input layer'\n",
        "        assert 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot train a model without an output layer'\n",
        "        assert self.loaded == False, 'You can not (re)train a model loaded from a file.'\n",
        "        assert 1 < n_epochs < 100, 'The number of epochs should be greater than 1 and lower than 100'\n",
        "        assert all(type(l) == list for l in (trainX, trainY, validX, validY)), 'trainX, trainY, validX and validY should all be lists'\n",
        "        assert all(len(l) > 0 for l in (trainX, trainY, validX, validY)), 'trainX, trainY, validX and validY should not be empty'\n",
        "\n",
        "        assert len(trainX) == len(trainY), 'trainX and trainY should have the same amount of samples'\n",
        "        assert len(trainX[0]) == 200 and len(trainX[0][0]) == 4 and type(trainX[0][0][0]) == int, 'trainX should have size (_, 200, 4) and should contain integers'\n",
        "        assert type(trainY[0]) == int, 'trainY should have length n (for n sequences) and should contain integers'\n",
        "\n",
        "        assert len(validX) == len(validY), 'validX and validY should have the same amount of samples'\n",
        "        assert len(validX[0]) == 200 and len(validX[0][0]) == 4 and type(validX[0][0][0]) == int, 'validX should have size (_, 200, 4) and should contain integers'\n",
        "        assert type(validY[0]) == int, 'validY should have length n (for n sequences) and should contain integers'\n",
        "        # assert input and output layer\n",
        "        self._prepare_training()\n",
        "\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        self.sess.run(tf.local_variables_initializer())\n",
        "        train_dataset = _Dataset(trainX, trainY)\n",
        "        valid_dataset = _Dataset(validX, validY)\n",
        "        self._printOutputClasses(train_dataset,'training')\n",
        "        self._printOutputClasses(valid_dataset,'validation')\n",
        "\n",
        "        best_valid_score = 999999\n",
        "        print()\n",
        "        print(' {:^5} | {:^14} | {:^14} | {:^11} | {:^11} | {:^8} '.format('epoch','train cost','valid cost','train acc','valid acc','time'))\n",
        "        print('-{:-^6}+{:-^16}+{:-^16}+{:-^13}+{:-^13}+{:-^9}-'.format('','','','','',''))\n",
        "\n",
        "        tr_cost, tr_acc = self._evaluateSet(train_dataset)\n",
        "        va_cost, va_acc = self._evaluateSet(valid_dataset)\n",
        "        print(' {:5d} |   {:2.8f}   |   {:2.8f}   |  {:1.7f}  | {:1.7f}  | {:4.2f}s '.format(0,tr_cost,tr_acc,va_cost,va_acc,0))\n",
        "\n",
        "        for epoch in range(1,n_epochs+1):\n",
        "            epoch_start_time = time.time()\n",
        "            epoch_finished = False\n",
        "            while not epoch_finished:\n",
        "                batch_x, batch_y, epoch_finished = train_dataset.next_batch(256)\n",
        "                self.sess.run(self.train_op, feed_dict={self.X_placeholder: batch_x, self.Y_placeholder: batch_y})\n",
        "            tr_cost, tr_acc = self._evaluateSet(train_dataset)\n",
        "            va_cost, va_acc = self._evaluateSet(valid_dataset)\n",
        "\n",
        "            if va_cost < best_valid_score:\n",
        "                best_valid_score = va_cost\n",
        "                message = '-> model selected'\n",
        "                self._storeNetworkParameters('models/tmp')\n",
        "            else:\n",
        "                message = ''\n",
        "            print(' {:5d} |   {:2.8f}   |   {:2.8f}   |  {:1.7f}  | {:1.7f}  | {:4.2f}s {}'.format(epoch,tr_cost,va_cost,tr_acc,va_acc,time.time()-epoch_start_time,message))\n",
        "\n",
        "        self._loadNetworkParameters('models/tmp')\n",
        "        print('Finished training')\n",
        "        print('####################################')\n",
        "\n",
        "    # Function to generate predictions for a certain dataset.\n",
        "    def generatePredictions(self, testX):\n",
        "        assert len(testX[0]) == 200 and len(testX[0][0]) == 4 and type(testX[0][0][0]) == int, 'testX should have size (_, 200, 4) and should contain integers'\n",
        "        assert self.loaded or 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot test a model without an input layer'\n",
        "        assert self.loaded or 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot test a model without an output layer'\n",
        "        # assert input and output layer\n",
        "        all_preds = []\n",
        "        for i in range(math.ceil(len(testX)/256)):\n",
        "            batch_x = np.asarray(testX[i*256:(i+1)*256])\n",
        "            preds = self.sess.run(self.predictions_softmax,feed_dict={self.X_placeholder:batch_x})\n",
        "            for i in range(len(preds)):\n",
        "                all_preds.append((preds[i][0],preds[i][1]))\n",
        "        return all_preds\n",
        "\n",
        "    # Function to save the model\n",
        "    def saveModel(self, file_to_save_to):\n",
        "        assert 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot save a model without an input layer'\n",
        "        assert 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot save a model without an output layer'\n",
        "        # assert input and output layer\n",
        "        assert not self.loaded, 'You cannot save a loaded model again.'\n",
        "        self._storeNetworkParameters('models/'+file_to_save_to)\n",
        "\n",
        "    def _prepare_training(self):\n",
        "        # assert all layers -1 == output layer\n",
        "        gs = tf.train.get_or_create_global_step()\n",
        "        self.predictions_softmax = tf.nn.softmax(self.all_layers[-1][-1],name='softmax_prediction')\n",
        "\n",
        "        self.cost_f = tf.losses.softmax_cross_entropy(onehot_labels=self.Y_placeholder, logits=self.all_layers[-1][-1])\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "        self.train_op = self.optimizer.minimize(loss=self.cost_f,global_step=gs)\n",
        "\n",
        "        self.acc_f, self.acc_op = tf.metrics.accuracy(labels=tf.argmax(self.Y_placeholder, axis=1),predictions=tf.argmax(self.predictions_softmax, axis=1),name='metric_acc')\n",
        "        self.metric_var_initializer = tf.variables_initializer(var_list=tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope='metric'))\n",
        "\n",
        "    def _evaluateSet(self, dataset):\n",
        "        self.sess.run(self.metric_var_initializer)\n",
        "        costs = []\n",
        "        batches_done = False\n",
        "        while not batches_done:\n",
        "            batch_x, batch_y, epoch_finished = dataset.next_batch(256)\n",
        "\n",
        "            cost_batch = self.sess.run(self.cost_f, feed_dict={self.X_placeholder: batch_x,self.Y_placeholder: batch_y})\n",
        "            _ = self.sess.run([self.acc_op], feed_dict={self.X_placeholder: batch_x,self.Y_placeholder: batch_y})\n",
        "            costs.extend([cost_batch] * len(batch_y))\n",
        "\n",
        "            if epoch_finished:\n",
        "                batches_done = True\n",
        "\n",
        "        accuracy = self.sess.run([self.acc_f])[0]\n",
        "        return np.average(costs),accuracy\n",
        "\n",
        "    def _printOutputClasses(self, dataset, label):\n",
        "        print()\n",
        "        counts = dataset.getClassCounts()\n",
        "        print('Number of {} examples: {}'.format(label,int(np.sum(counts))))\n",
        "        if len(counts) > 1:\n",
        "            print('Distribution of the {} set:'.format(label))\n",
        "            for i in range(min(10,len(counts))):\n",
        "                print('  # elements of class {} = {}'.format(i,int(counts[i])))\n",
        "\n",
        "    def _storeNetworkParameters(self, saveToDir):\n",
        "        try:\n",
        "            saver = tf.train.Saver()\n",
        "            if not os.path.exists(saveToDir):\n",
        "                os.makedirs(saveToDir)\n",
        "            saver.save(self.sess,saveToDir+'/'+saveToDir[saveToDir.rfind('/')+1:])\n",
        "        except Exception:\n",
        "            print('SOMETHING WENT WRONG WITH STORING SHIT JASPER!! ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "            print(sys.exc_info())\n",
        "            print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "\n",
        "    def _loadNetworkParameters(self, saveToDir):\n",
        "        filename = saveToDir+'/'+saveToDir[saveToDir.rfind('/')+1:]\n",
        "        if self.loaded:\n",
        "            saver = tf.train.import_meta_graph(filename+'.meta')\n",
        "        else:\n",
        "            saver = tf.train.Saver()\n",
        "        saver.restore(self.sess, tf.train.latest_checkpoint(saveToDir))\n",
        "\n",
        "\n",
        "class _Dataset:\n",
        "\n",
        "    def __init__(self,x_data,y_data=None):\n",
        "        if isinstance(x_data,list):\n",
        "            x_data = np.asarray(x_data)\n",
        "\n",
        "        self.index_in_epoch = 0\n",
        "        self.x_data = x_data\n",
        "        self.num_samples = x_data.shape[0]\n",
        "\n",
        "        if y_data:\n",
        "            if isinstance(y_data,list):\n",
        "                y_data = self._convertY(y_data)\n",
        "                self.y_data = y_data\n",
        "        else:\n",
        "            self.y_data = []\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def getClassCounts(self):\n",
        "        return np.sum(self.y_data,axis=0)\n",
        "\n",
        "    def _convertY(self, y_data):\n",
        "        out = np.zeros((len(y_data),2))\n",
        "        for i,cl in enumerate(y_data):\n",
        "            out[i][cl] = 1\n",
        "        return out\n",
        "\n",
        "    def next_batch(self,batch_size):\n",
        "        start = self.index_in_epoch\n",
        "        end = self.index_in_epoch + batch_size\n",
        "\n",
        "        if start == 0:\n",
        "            idx = np.arange(0, self.num_samples)  # get all possible indexes\n",
        "            np.random.shuffle(idx)  # shuffle indexes\n",
        "            self.x_data = self.x_data[idx]\n",
        "            if len(self.y_data) > 0:\n",
        "                self.y_data = self.y_data[idx]\n",
        "\n",
        "        if end < self.num_samples:\n",
        "            self.index_in_epoch = end\n",
        "            return self.x_data[start:end], self.y_data[start:end], False # epoch finished = False\n",
        "        else:\n",
        "            self.index_in_epoch = 0\n",
        "            return self.x_data[start:], self.y_data[start:], True #epoch finished = True\n",
        "\n",
        "\n",
        "    def stepsInEpoch(self,batch_size):\n",
        "        return math.ceil(len(self) / batch_size)\n",
        "\n",
        "    def getX(self):\n",
        "        return self.x_data\n",
        "\n",
        "    def getSequenceLength(self):\n",
        "        return len(self.x_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThP9xbGdURIP",
        "outputId": "f9550ac7-1fe9-475c-8dcc-102194e1ab1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readInputs(f1,f2):\n",
        "    lines_pos = open(f1).readlines()\n",
        "    lines_neg = open(f2).readlines()\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for l in convertLines(lines_pos):\n",
        "        X.append(l)\n",
        "        Y.append(1)\n",
        "    for l in convertLines(lines_neg):\n",
        "        X.append(l)\n",
        "        Y.append(0)\n",
        "\n",
        "    return X,Y\n",
        "\n",
        "def convertLines(lines):\n",
        "    v = []\n",
        "    newLines = []\n",
        "    for line in lines:\n",
        "        newline = []\n",
        "        for c in line.strip():\n",
        "            if c == 'A':\n",
        "                v = [1,0,0,0]\n",
        "            elif c == 'C':\n",
        "                v = [0,1,0,0]\n",
        "            elif c == 'G':\n",
        "                v = [0,0,1,0]\n",
        "            elif c == 'T':\n",
        "                v = [0,0,0,1]\n",
        "            newline.append(v)\n",
        "        newLines.append(newline)\n",
        "    return newLines"
      ],
      "metadata": {
        "id": "w2dq5OG0Uk0o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regular_network():\n",
        "    net_model = NetworkModel()\n",
        "    net_model.addInputLayer()\n",
        "    net_model.addFullyConnectedLayer(50)\n",
        "    net_model.addFullyConnectedLayer(50)\n",
        "    net_model.addOutputLayer()\n",
        "    return net_model"
      ],
      "metadata": {
        "id": "JoZ0H8yyU2IK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nm = regular_network()\n",
        "nm.printDetails()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itDzM6QiU6hF",
        "outputId": "c74b2e27-7d73-4c92-c572-2be2fa5fa5ca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################\n",
            "Network information:\n",
            "This network has 42702 trainable parameters.\n",
            " 0. Input layer                                                                -> Output size: (?, 200, 4)\n",
            " 1. Flatten layer                                                              -> Output size: (?, 800)\n",
            " 2. Fully-connected layer   50 neurons, with ReLU                              -> Output size: (?, 50)\n",
            " 3. Fully-connected layer   50 neurons, with ReLU                              -> Output size: (?, 50)\n",
            " 4. Softmax (output) layer  2 neurons                                          -> Output size: (?, 2)\n",
            "\n",
            "####################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:523: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X, y = readInputs('pos.fa', 'neg.fa')\n",
        "#так не сработало, видимо, необходимо конвертировать в txt"
      ],
      "metadata": {
        "id": "O9fjBHp1U-pF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython\n",
        "\n",
        "from Bio import SeqIO\n",
        "\n",
        "with open(\"pos.txt\", \"w\") as f:\n",
        "    for record in SeqIO.parse(\"pos.fa\", \"fasta\"):\n",
        "        print(record.upper().seq, file=f)\n",
        "with open(\"neg.txt\", \"w\") as f:\n",
        "    for record in SeqIO.parse(\"neg.fa\", \"fasta\"):\n",
        "        print(record.upper().seq, file=f)\n",
        "        print(len(record.upper().seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tyv1HWzW-fA",
        "outputId": "77039443-590c-49a3-e66d-d3cee3c33d69"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = readInputs('pos.txt', 'neg.txt')"
      ],
      "metadata": {
        "id": "8XdJUvMxaAPi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.3, random_state=29)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test1, y_test1, test_size=0.5, random_state=29)"
      ],
      "metadata": {
        "id": "Z6GRLpBeVb6Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_network():\n",
        "    con_model = NetworkModel()\n",
        "    con_model.addInputLayer()\n",
        "    con_model.addConvLayer(10, 7)\n",
        "    con_model.addMaxPoolLayer(5)\n",
        "    con_model.addConvLayer(20, 5)\n",
        "    con_model.addMaxPoolLayer(5)\n",
        "    con_model.addFullyConnectedLayer(15)\n",
        "    con_model.addOutputLayer()\n",
        "    return con_model"
      ],
      "metadata": {
        "id": "xYiBfOGyVkHQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = conv_network()\n",
        "cnn.printDetails()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-bMj6s0VwDw",
        "outputId": "93d9e85f-55c1-4f80-b0c6-9924de54d677"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################\n",
            "Network information:\n",
            "This network has 3757 trainable parameters.\n",
            " 0. Input layer                                                                -> Output size: (?, 200, 4)\n",
            " 1. Convolutional layer     10 filters, width 7, zero padding, with ReLU       -> Output size: (?, 200, 10)\n",
            " 2. Max pooling layer       pool size 5                                        -> Output size: (?, 40, 10)\n",
            " 3. Convolutional layer     20 filters, width 5, zero padding, with ReLU       -> Output size: (?, 40, 20)\n",
            " 4. Max pooling layer       pool size 5                                        -> Output size: (?, 8, 20)\n",
            " 5. Flatten layer                                                              -> Output size: (?, 160)\n",
            " 6. Fully-connected layer   15 neurons, with ReLU                              -> Output size: (?, 15)\n",
            " 7. Softmax (output) layer  2 neurons                                          -> Output size: (?, 2)\n",
            "\n",
            "####################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:288: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: `tf.layers.max_pooling1d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling1D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/pooling.py:294: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:523: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.train(X_train, y_train, X_val, y_val, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hh4iDIV2Gy",
        "outputId": "44dfc835-9b6c-46c8-8391-fc0e359b5ece"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################\n",
            "\n",
            "Number of training examples: 900\n",
            "Distribution of the training set:\n",
            "  # elements of class 0 = 696\n",
            "  # elements of class 1 = 204\n",
            "\n",
            "Number of validation examples: 194\n",
            "Distribution of the validation set:\n",
            "  # elements of class 0 = 147\n",
            "  # elements of class 1 = 47\n",
            "\n",
            " epoch |   train cost   |   valid cost   |  train acc  |  valid acc  |   time   \n",
            "-------+----------------+----------------+-------------+-------------+----------\n",
            "     0 |   0.79980654   |   0.27000001   |  0.8064193  | 0.2577319  | 0.00s \n",
            "     1 |   0.56468779   |   0.58878142   |  0.7733333  | 0.7577320  | 0.86s -> model selected\n",
            "     2 |   0.56725228   |   0.59669310   |  0.7733333  | 0.7577320  | 0.31s \n",
            "     3 |   0.51620221   |   0.53999466   |  0.7733333  | 0.7577320  | 0.57s -> model selected\n",
            "     4 |   0.48658243   |   0.50120246   |  0.7733333  | 0.7577320  | 0.87s -> model selected\n",
            "     5 |   0.47504941   |   0.48538500   |  0.7733333  | 0.7783505  | 0.38s -> model selected\n",
            "     6 |   0.45044747   |   0.46221668   |  0.7800000  | 0.7886598  | 0.40s -> model selected\n",
            "     7 |   0.42717355   |   0.44392827   |  0.7733333  | 0.7783505  | 0.39s -> model selected\n",
            "     8 |   0.41222170   |   0.43208510   |  0.7800000  | 0.7783505  | 0.41s -> model selected\n",
            "     9 |   0.38888142   |   0.40320352   |  0.8100000  | 0.8247423  | 0.41s -> model selected\n",
            "    10 |   0.37313491   |   0.38312790   |  0.8466667  | 0.8402062  | 0.41s -> model selected\n",
            "    11 |   0.35605028   |   0.36841559   |  0.8500000  | 0.8402062  | 0.44s -> model selected\n",
            "    12 |   0.34389472   |   0.36020637   |  0.8500000  | 0.8402062  | 0.44s -> model selected\n",
            "    13 |   0.33290690   |   0.34725684   |  0.8622222  | 0.8247423  | 0.46s -> model selected\n",
            "    14 |   0.32675794   |   0.33737272   |  0.8733333  | 0.8350515  | 0.44s -> model selected\n",
            "    15 |   0.32055739   |   0.33565572   |  0.8711111  | 0.8350515  | 0.46s -> model selected\n",
            "    16 |   0.31755236   |   0.33657530   |  0.8744444  | 0.8350515  | 0.20s \n",
            "    17 |   0.31531590   |   0.33647230   |  0.8755556  | 0.8350515  | 0.20s \n",
            "    18 |   0.31233877   |   0.33240226   |  0.8766667  | 0.8402062  | 0.46s -> model selected\n",
            "    19 |   0.31144905   |   0.32846522   |  0.8788889  | 0.8350515  | 0.49s -> model selected\n",
            "    20 |   0.30971470   |   0.33712938   |  0.8800000  | 0.8350515  | 0.21s \n",
            "INFO:tensorflow:Restoring parameters from models/tmp/tmp\n",
            "Finished training\n",
            "####################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RaGkCL95V8MJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
